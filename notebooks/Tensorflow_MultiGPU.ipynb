{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# 4. Change data-order from NHWC to NCHW to improve speed\n",
    "\n",
    "# 5. IMPORTANT: For inference the symbol probably requires a training:false flag\n",
    "# 6. IMPORTANT: See if tfrecords reduces IO latency\n",
    "# 7. IMPORTANT: Multi-gpu wrapper????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nets import densenet  # Download from https://github.com/pudae/tensorflow-densenet\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework.ops import convert_to_tensor\n",
    "from tensorflow.contrib.data import Iterator\n",
    "from tensorflow.contrib.slim.python.slim.nets import resnet_v1\n",
    "from PIL import Image\n",
    "import random\n",
    "from common.utils import download_data_chextxray, get_imgloc_labels, get_train_valid_test_split\n",
    "from common.utils import compute_roc_auc\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs:  12\n"
     ]
    }
   ],
   "source": [
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "print(\"CPUs: \", CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "CLASSES = 14\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "LR = 0.0001  # Effective learning-rate will decrease as BATCHSIZE rises\n",
    "EPOCHS = 5\n",
    "BATCHSIZE = 64  # Chainer auto scales batch\n",
    "IMAGENET_RGB_MEAN = np.array([123.68, 116.78, 103.94], dtype=np.float32)\n",
    "IMAGENET_SCALE_FACTOR = 0.017\n",
    "TOT_PATIENT_NUMBER = 30805  # From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestxray/images chestxray/Data_Entry_2017.csv\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "print(IMAGE_FOLDER, LABEL_FILE)\n",
    "# Model checkpoint\n",
    "PRETRAINED_WEIGHTS = True\n",
    "CHKPOINT = 'tfdensenet/tf-densenet121.ckpt'\n",
    "CHKPOINT = 'resnet_v1_50.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 667 ms, sys: 208 ms, total: 875 ms\n",
      "Wall time: 874 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayData():\n",
    "    \n",
    "    def __init__(self, img_dir, lbl_file, patient_ids, mode='inference', \n",
    "                 width=WIDTH, height=HEIGHT, batch_size=BATCHSIZE, \n",
    "                 imagenet_mean=IMAGENET_RGB_MEAN, imagenet_scaling = IMAGENET_SCALE_FACTOR,\n",
    "                 shuffle=True):\n",
    "        # Get data\n",
    "        self.img_locs, self.labels = get_imgloc_labels(img_dir, lbl_file, patient_ids)\n",
    "        self.data_size = len(self.labels)\n",
    "        self.imagenet_mean = imagenet_mean\n",
    "        self.imagenet_scaling = imagenet_scaling\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        # Create dataset\n",
    "        # Performance: https://www.tensorflow.org/versions/master/performance/datasets_performance\n",
    "        # Following: https://stackoverflow.com/a/48096625/6772173\n",
    "        data = tf.data.Dataset.from_tensor_slices((self.img_locs, self.labels))\n",
    "        # Processing\n",
    "        if mode == 'training':\n",
    "            data = data.shuffle(self.data_size).map(self._parse_function_train,\n",
    "                            num_parallel_calls=CPU_COUNT).prefetch(10*batch_size).batch(batch_size)\n",
    "        else:\n",
    "            data = data.map(self._parse_function_inference,\n",
    "                            num_parallel_calls=CPU_COUNT).prefetch(10*batch_size).batch(batch_size)\n",
    "        \n",
    "        self.data = data        \n",
    "        print(\"Loaded {} labels and {} images\".format(len(self.labels), len(self.img_locs)))\n",
    "        \n",
    "        \n",
    "    def _parse_function_train(self, filename, label):\n",
    "        img_rgb, label = self._preprocess_image_labels(filename, label)\n",
    "        # Super high CPU usuage bottlenecking GPU\n",
    "        # Random crop\n",
    "        img_rgb = tf.image.resize_images(img_rgb, [self.height+40, self.width+40])\n",
    "        img_rgb = tf.random_crop(img_rgb, [self.height, self.width, 3])\n",
    "        # Random flip\n",
    "        img_rgb = tf.image.random_flip_left_right(img_rgb)\n",
    "        # Random rotation\n",
    "        rot_angle = np.random.randint(-10, 10)\n",
    "        img_rgb = tf.contrib.image.rotate(img_rgb, rot_angle)\n",
    "        return img_rgb, label\n",
    "        \n",
    "        \n",
    "    def _parse_function_inference(self, filename, label):\n",
    "        img_rgb, label = self._preprocess_image_labels(filename, label)\n",
    "        # Resize to final dimensions\n",
    "        img_rgb = tf.image.resize_images(img_rgb, [self.height, self.width])\n",
    "        return img_rgb, label \n",
    "       \n",
    "    \n",
    "    def _preprocess_image_labels(self, filename, label):\n",
    "        # load and preprocess the image\n",
    "        img_decoded = tf.to_float(tf.image.decode_png(tf.read_file(filename), channels=3))\n",
    "        img_centered = tf.subtract(img_decoded, self.imagenet_mean)\n",
    "        img_rgb = img_centered * self.imagenet_scaling\n",
    "        return img_rgb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:21563 valid:3080 test:6162\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set, test_set = get_train_valid_test_split(TOT_PATIENT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87306 labels and 87306 images\n",
      "Loaded 7616 labels and 7616 images\n",
      "Loaded 17198 labels and 17198 images\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # Create dataset for iterator\n",
    "    train_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=train_set,  mode='training')\n",
    "    valid_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=valid_set, shuffle=False)\n",
    "    test_dataset  = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=test_set, shuffle=False)\n",
    "    \n",
    "    # Create an reinitializable iterator given the dataset structure\n",
    "    iterator = Iterator.from_structure(train_dataset.data.output_types,\n",
    "                                       train_dataset.data.output_shapes)\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(model_name, in_tensor, is_training,\n",
    "               chkpoint=CHKPOINT, out_features=CLASSES):\n",
    "    if model_name == 'resnet50':\n",
    "        # Load variables into model (without this nothing is restored)\n",
    "        tf.train.get_or_create_global_step()\n",
    "        # Import symbol\n",
    "        with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "            base_model, _ = resnet_v1.resnet_v1_50(X, num_classes=None, \n",
    "                                                   is_training=is_training)\n",
    "        # Collect variables to restore from checkpoint\n",
    "        variables_to_restore = slim.get_variables_to_restore()\n",
    "        #print(variables_to_restore)\n",
    "        init_fn = slim.assign_from_checkpoint_fn(chkpoint, variables_to_restore)   \n",
    "        # Attach extra layers\n",
    "        fc = tf.layers.dense(base_model, out_features, name='output')\n",
    "        # Activation function will be included in loss\n",
    "        sym = tf.reshape(fc, shape=[-1, out_features])\n",
    "        \n",
    "    elif model_name == 'densenet121':\n",
    "        # Load variables into model (without this nothing is restored)\n",
    "        tf.train.get_or_create_global_step()\n",
    "        # Import symbol\n",
    "        dense_args = densenet.densenet_arg_scope()\n",
    "        print(dense_args)\n",
    "        #dense_args[data_format]='NCHW'\n",
    "        with slim.arg_scope(dense_args):\n",
    "            logits, _ = densenet.densenet121(X, num_classes=out_features,\n",
    "                                             reuse=None, is_training=is_training)\n",
    "        # Collect variables to restore from checkpoint\n",
    "        variables_to_restore = slim.get_variables_to_restore(\n",
    "            exclude=['densenet121/logits', 'predictions'])\n",
    "        #print(variables_to_restore)\n",
    "        init_fn = slim.assign_from_checkpoint_fn(chkpoint, variables_to_restore)  \n",
    "        # Reshape logits to (None, CLASSES) since my label is (None, CLASSES)\n",
    "        sym = tf.reshape(logits, shape=[-1, CLASSES])\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unknown model-name\")\n",
    "        \n",
    "    return sym, init_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_symbol(sym, out_tensor, lr=LR):\n",
    "    loss_fn = tf.nn.sigmoid_cross_entropy_with_logits(logits=sym, labels=y)\n",
    "    loss = tf.reduce_mean(loss_fn)\n",
    "    optimizer = tf.train.AdamOptimizer(lr, beta1=0.9, beta2=0.999)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    return training_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if len(not_initialized_vars):\n",
    "        #print(\"Initialising: \", not_initialized_vars)\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 827 ms, total: 4.15 s\n",
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Place-holders\n",
    "sess = tf.Session()\n",
    "X = tf.placeholder(tf.float32, shape=[None, WIDTH, HEIGHT, CHANNELS])\n",
    "y = tf.placeholder(tf.float32, shape=[None, CLASSES])\n",
    "training = tf.placeholder(tf.bool) \n",
    "# Create symbol (for training and inference)\n",
    "sym, init_fn = get_symbol(model_name='resnet50', in_tensor=X, is_training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training operation\n",
    "model, loss = init_symbol(sym=sym, out_tensor=y)\n",
    "# Create iterator\n",
    "training_init_op = iterator.make_initializer(train_dataset.data)\n",
    "train_batches_per_epoch = int(np.floor(train_dataset.data_size/BATCHSIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from resnet_v1_50.ckpt\n",
      "CPU times: user 2.82 s, sys: 862 ms, total: 3.68 s\n",
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Restoring parameters from tfdensenet/tf-densenet121.ckpt\n",
    "init_fn(sess)\n",
    "# Initialise uninitialised vars (FC layer & Adam)\n",
    "init_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1\n",
      "Average loss: 0.1613440364599228\n",
      "Epoch time: 604 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Epoch number: 2\n",
      "Average loss: 0.1491870880126953\n",
      "Epoch time: 602 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Epoch number: 3\n",
      "Average loss: 0.1451054960489273\n",
      "Epoch time: 601 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Epoch number: 4\n",
      "Average loss: 0.14188571274280548\n",
      "Epoch time: 599 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Epoch number: 5\n",
      "Average loss: 0.13917018473148346\n",
      "Epoch time: 600 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "CPU times: user 8h 27min 57s, sys: 10min 40s, total: 8h 38min 38s\n",
      "Wall time: 50min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#1hr3min\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print(\"Epoch number: {}\".format(epoch+1))\n",
    "    # Logging\n",
    "    epoch_loss = []\n",
    "    stime = time.time()\n",
    "    # Initialize iterator with the training dataset\n",
    "    sess.run(training_init_op)\n",
    "    for step in range(train_batches_per_epoch):\n",
    "        \n",
    "        # get next batch of data\n",
    "        img_batch, label_batch = sess.run(next_batch)\n",
    "        # And run the training op\n",
    "        _, loss_tr = sess.run([model, loss], feed_dict={X: img_batch, y: label_batch, training: True})\n",
    "        epoch_loss.append(loss_tr)\n",
    "        \n",
    "    etime = time.time()\n",
    "    print(\"Average loss: {}\".format(np.mean(epoch_loss)))\n",
    "    # 7min20s for chainer\n",
    "    print(\"Epoch time: {0:.0f} seconds\".format(etime-stime))\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 55s, sys: 10.4 s, total: 17min 5s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test\n",
    "testing_init_op = iterator.make_initializer(test_dataset.data)\n",
    "sess.run(testing_init_op)\n",
    "\n",
    "test_batches_per_epoch = int(np.floor(test_dataset.data_size/BATCHSIZE))\n",
    "pred = tf.sigmoid(sym)\n",
    "y_guess = []\n",
    "y_truth = []\n",
    "\n",
    "for step in range(test_batches_per_epoch):\n",
    "    img_batch, label_batch = sess.run(next_batch)\n",
    "    output = sess.run(pred, feed_dict={X: img_batch, training: True})\n",
    "    y_guess.append(output)\n",
    "    y_truth.append(label_batch)\n",
    "        \n",
    "# Concatenate\n",
    "y_guess = np.concatenate(y_guess, axis=0)\n",
    "y_truth = np.concatenate(y_truth, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full AUC [0.8067662388310473, 0.8516482589811255, 0.7805391403572336, 0.8824562675781004, 0.8702802591190884, 0.8878719432811005, 0.6949038142574767, 0.8819361474680872, 0.6130602438290237, 0.834636699950543, 0.725231232059445, 0.7848622615438152, 0.7481382714648435, 0.8461683326513139]\n",
      "Test AUC: 0.8006\n"
     ]
    }
   ],
   "source": [
    "print(\"Test AUC: {0:.4f}\".format(compute_roc_auc(y_truth, y_guess, classes=CLASSES)))\n",
    "# 0.5211 (training:false)\n",
    "# 0.6408 (training:true)??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
