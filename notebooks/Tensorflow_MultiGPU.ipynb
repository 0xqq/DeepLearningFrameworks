{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Summary\n",
    "# 1. Tensorflow Multi-GPU example using Estimator & Dataset high-APIs\n",
    "# 2. On-the-fly data-augmentation (random crop, random flip)\n",
    "# ToDo:\n",
    "# 2. Add validation-data to estimator.train()\n",
    "# 3. Investigate tfrecord speed improvement (to match MXNet)\n",
    "# References:\n",
    "# https://www.tensorflow.org/performance/performance_guide\n",
    "# 1. https://jhui.github.io/2017/03/07/TensorFlow-Perforamnce-and-advance-topics/\n",
    "# 2. https://www.tensorflow.org/versions/master/performance/datasets_performance\n",
    "# 3. https://github.com/pudae/tensorflow-densenet\n",
    "# 4. https://stackoverflow.com/a/48096625/6772173\n",
    "# 5. https://stackoverflow.com/questions/47867748/transfer-learning-with-tf-estimator-estimator-framework\n",
    "# 6. https://github.com/BobLiu20/Classification_Nets/blob/master/tensorflow/common/average_gradients.py\n",
    "# 7. https://github.com/BobLiu20/Classification_Nets/blob/master/tensorflow/training/train_estimator.py\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_GPU = True  # TOGGLE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# Download model check-point and module from below repo:\n",
    "#wget -N https://github.com/pudae/tensorflow-densenet/raw/master/nets/densenet.py\n",
    "#wget -N https://ikpublictutorial.blob.core.windows.net/deeplearningframeworks/tf-densenet121.tar.gz\n",
    "#tar xzvf tf-densenet121.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework.ops import convert_to_tensor\n",
    "from tensorflow.contrib.data import Iterator\n",
    "from common.utils import download_data_chextxray, get_imgloc_labels, get_train_valid_test_split\n",
    "from common.utils import compute_roc_auc, get_cuda_version, get_cudnn_version, get_gpu_name\n",
    "from common.params_dense import *\n",
    "slim = tf.contrib.slim\n",
    "import densenet  # Download from https://github.com/pudae/tensorflow-densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Numpy:  1.14.2\n",
      "Tensorflow:  1.6.0\n",
      "GPU:  ['Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Tensorflow: \", tf.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs:  24\n",
      "GPUs:  4\n"
     ]
    }
   ],
   "source": [
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "GPU_COUNT = len(get_gpu_name())\n",
    "print(\"CPUs: \", CPU_COUNT)\n",
    "print(\"GPUs: \", GPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestxray/images chestxray/Data_Entry_2017.csv\n"
     ]
    }
   ],
   "source": [
    "# Model-params\n",
    "IMAGENET_RGB_MEAN_CAFFE = np.array([123.68, 116.78, 103.94], dtype=np.float32)\n",
    "IMAGENET_SCALE_FACTOR_CAFFE = 0.017\n",
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "print(IMAGE_FOLDER, LABEL_FILE)\n",
    "CHKPOINT = 'tf-densenet121.ckpt'  # Downloaded tensorflow-checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually scale to multi-gpu\n",
    "if MULTI_GPU:\n",
    "    LR *= GPU_COUNT \n",
    "    BATCHSIZE *= GPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 659 ms, sys: 234 ms, total: 893 ms\n",
      "Wall time: 892 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayData():\n",
    "    \n",
    "    def __init__(self, img_dir, lbl_file, patient_ids, mode='inference', \n",
    "                 width=WIDTH, height=HEIGHT, batch_size=BATCHSIZE, \n",
    "                 imagenet_mean=IMAGENET_RGB_MEAN_CAFFE, imagenet_scaling = IMAGENET_SCALE_FACTOR_CAFFE,\n",
    "                 buffer=10):\n",
    "\n",
    "        self.img_locs, self.labels = get_imgloc_labels(img_dir, lbl_file, patient_ids)\n",
    "        self.data_size = len(self.labels)\n",
    "        self.imagenet_mean = imagenet_mean\n",
    "        self.imagenet_scaling = imagenet_scaling\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        data = tf.data.Dataset.from_tensor_slices((self.img_locs, self.labels))\n",
    "        \n",
    "        # Processing\n",
    "        # Output as channels-last and TF model will reshape in densenet.py\n",
    "        # inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "        if mode == 'training':\n",
    "            data = data.shuffle(self.data_size).repeat().apply(\n",
    "                tf.contrib.data.map_and_batch(self._parse_function_train, batch_size)).prefetch(buffer)\n",
    "        elif mode == 'inference':\n",
    "            data = data.apply(\n",
    "                tf.contrib.data.map_and_batch(self._parse_function_inference, batch_size)).prefetch(buffer)\n",
    "        \n",
    "        self.data = data        \n",
    "        print(\"Loaded {} labels and {} images\".format(len(self.labels), len(self.img_locs)))\n",
    "        \n",
    "        \n",
    "    def _parse_function_train(self, filename, label):\n",
    "        img_rgb, label = self._preprocess_image_labels(filename, label)\n",
    "        # Random crop (from 264x264)\n",
    "        img_rgb = tf.image.resize_images(img_rgb, [self.height+40, self.width+40])\n",
    "        img_rgb = tf.random_crop(img_rgb, [self.height, self.width, 3])\n",
    "        # Random flip\n",
    "        img_rgb = tf.image.random_flip_left_right(img_rgb)\n",
    "        # Channels-first\n",
    "        img_rgb = tf.transpose(img_rgb, [2, 0, 1])\n",
    "        return img_rgb, label\n",
    "        \n",
    "        \n",
    "    def _parse_function_inference(self, filename, label):\n",
    "        img_rgb, label = self._preprocess_image_labels(filename, label)\n",
    "        # Resize to final dimensions\n",
    "        img_rgb = tf.image.resize_images(img_rgb, [self.height, self.width])\n",
    "        # Channels-first\n",
    "        img_rgb = tf.transpose(img_rgb, [2, 0, 1])\n",
    "        return img_rgb, label \n",
    "       \n",
    "    \n",
    "    def _preprocess_image_labels(self, filename, label):\n",
    "        # load and preprocess the image\n",
    "        img_decoded = tf.to_float(tf.image.decode_png(tf.read_file(filename), channels=3))\n",
    "        img_centered = tf.subtract(img_decoded, self.imagenet_mean)\n",
    "        img_rgb = img_centered * self.imagenet_scaling\n",
    "        return img_rgb, tf.cast(label, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:21563 valid:3080 test:6162\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set, test_set = get_train_valid_test_split(TOT_PATIENT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87306 labels and 87306 images\n",
      "Loaded 7616 labels and 7616 images\n",
      "Loaded 17198 labels and 17198 images\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # Create dataset for iterator\n",
    "    train_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=train_set,  \n",
    "                             mode='training')\n",
    "    valid_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=valid_set)\n",
    "    test_dataset  = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "            grads.append(expanded_g)\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(model_name, in_tensor, is_training, chkpoint, out_features):\n",
    "    if model_name == 'densenet121':\n",
    "         # Import symbol\n",
    "        dense_args = densenet.densenet_arg_scope(data_format=\"NCHW\")\n",
    "        # Maybe also needs fused batch-norm?\n",
    "        print(dense_args)\n",
    "        with slim.arg_scope(dense_args):\n",
    "            base_model, _ = densenet.densenet121(in_tensor,\n",
    "                                                 num_classes=out_features,\n",
    "                                                 is_training=is_training)\n",
    "            # Need to reshape from (?, 1, 1, 14) to (?, 14)\n",
    "            sym = tf.reshape(base_model, shape=[-1, out_features])\n",
    "        # Collect variables to restore from checkpoint\n",
    "        variables_to_restore = slim.get_variables_to_restore(exclude=['densenet121/logits', 'predictions'])\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model-name\")\n",
    "    return sym, variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Create symbol\n",
    "    # is_training=True? | https://github.com/tensorflow/models/issues/3556\n",
    "    sym, variables_to_restore = get_symbol(\n",
    "        model_name=params[\"model_name\"],\n",
    "        in_tensor=features, \n",
    "        #is_training=(mode == tf.estimator.ModeKeys.TRAIN),\n",
    "        is_training=True,\n",
    "        chkpoint=params[\"checkpoint\"],\n",
    "        out_features=params[\"n_classes\"])\n",
    "    # ModeKeys.PREDICT\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=tf.sigmoid(sym))\n",
    "    # Optimizer & Loss\n",
    "    optimizer = tf.train.AdamOptimizer(params['lr'], beta1=0.9, beta2=0.999)\n",
    "    loss_fn = tf.losses.sigmoid_cross_entropy(labels, sym)\n",
    "    loss = tf.reduce_mean(loss_fn)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.train.init_from_checkpoint(params['checkpoint'], \n",
    "                              {v.name.split(':')[0]: v for v in variables_to_restore})\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss,\n",
    "        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_multigpu(features, labels, mode, params):\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Create symbol\n",
    "        sym, _ = get_symbol(\n",
    "            model_name=params[\"model_name\"],\n",
    "            in_tensor=features, \n",
    "            is_training=True,\n",
    "            chkpoint=params[\"checkpoint\"],\n",
    "            out_features=params[\"n_classes\"])\n",
    "        \n",
    "        # Predictions\n",
    "        predictions = tf.sigmoid(sym)   \n",
    "        # ModeKeys.PREDICT\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # Make sure splits sum to batch-size\n",
    "        split_size = params[\"batchsize\"] // len(params[\"gpus\"])\n",
    "        splits = [split_size, ] * (len(params[\"gpus\"]) - 1)\n",
    "        splits.append(params[\"batchsize\"] - split_size * (\n",
    "            len(params[\"gpus\"]) - 1))\n",
    "        # Split the features and labels\n",
    "        features_split = tf.split(features, splits, axis=0)\n",
    "        labels_split = tf.split(labels, splits, axis=0)\n",
    "        tower_grads = []\n",
    "        # Training operation\n",
    "        global_step = tf.train.get_global_step()\n",
    "        optimizer = tf.train.AdamOptimizer(LR, beta1=0.9, beta2=0.999)\n",
    "        # Load model on multiple GPUs\n",
    "        restore_list = []\n",
    "        with tf.variable_scope(tf.get_variable_scope()):\n",
    "            for i in range(len(params['gpus'])):\n",
    "                with tf.device('/gpu:%d' % i):\n",
    "                    with tf.name_scope('%s_%d' % (\"classification\", i)) as scope:\n",
    "                        # Symbol\n",
    "                        sym, variables_to_restore = get_symbol(\n",
    "                            model_name=params[\"model_name\"],\n",
    "                            in_tensor=features_split[i], \n",
    "                            is_training=True,\n",
    "                            chkpoint=params[\"checkpoint\"],\n",
    "                            out_features=params[\"n_classes\"])\n",
    "                        # Since reuse only need [0]\n",
    "                        restore_list.append(variables_to_restore)\n",
    "                        # Loss\n",
    "                        tf.losses.sigmoid_cross_entropy(labels_split[i], sym)\n",
    "                        # Training-ops\n",
    "                        update_ops = tf.get_collection(\n",
    "                            tf.GraphKeys.UPDATE_OPS, scope)\n",
    "                        updates_op = tf.group(*update_ops)\n",
    "                        with tf.control_dependencies([updates_op]):\n",
    "                            losses = tf.get_collection(tf.GraphKeys.LOSSES, scope)\n",
    "                            print(losses)\n",
    "                            total_loss = tf.add_n(losses, name='total_loss')\n",
    "                        # reuse var\n",
    "                        tf.get_variable_scope().reuse_variables()\n",
    "                        # grad compute\n",
    "                        grads = optimizer.compute_gradients(total_loss)\n",
    "                        tower_grads.append(grads)\n",
    "\n",
    "        # We must calculate the mean of each gradient\n",
    "        grads = average_gradients(tower_grads)\n",
    "        # Apply the gradients to adjust the shared variables.\n",
    "        apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "        # Group all updates to into a single train op.\n",
    "        train_op = tf.group(apply_gradient_op)\n",
    "        # Initialise from checkpoint\n",
    "        tf.train.init_from_checkpoint(params['checkpoint'], \n",
    "                              {v.name.split(':')[0]: v for v in restore_list[0]})\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=total_loss,\n",
    "            train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return train_dataset.data.make_one_shot_iterator().get_next()\n",
    "def valid_input_fn():\n",
    "    return valid_dataset.data.make_one_shot_iterator().get_next()\n",
    "def test_input_fn():\n",
    "    return test_dataset.data.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpizx8jhl7\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_summary_steps': 100, '_session_config': None, '_tf_random_seed': None, '_task_id': 0, '_evaluation_master': '', '_service': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8590f6b7f0>, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_master': '', '_model_dir': '/tmp/tmpizx8jhl7', '_keep_checkpoint_max': 5, '_global_id_in_cluster': 0}\n",
      "CPU times: user 4.42 ms, sys: 110 µs, total: 4.53 ms\n",
      "Wall time: 4.14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Estimator\n",
    "if MULTI_GPU:\n",
    "    nn = tf.estimator.Estimator(model_fn=model_fn_multigpu,\n",
    "                                params={\"lr\":LR, \n",
    "                                        \"checkpoint\":CHKPOINT,\n",
    "                                        \"n_classes\":CLASSES,\n",
    "                                        \"batchsize\":BATCHSIZE,\n",
    "                                        \"gpus\":list(range(GPU_COUNT)),\n",
    "                                        \"model_name\":\"densenet121\"})\n",
    "else:\n",
    "    nn = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                params={\"lr\":LR, \n",
    "                                        \"checkpoint\":CHKPOINT,\n",
    "                                        \"n_classes\":CLASSES,\n",
    "                                        \"model_name\":\"densenet121\"})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable global_step:0 from checkpoint tf-densenet121.ckpt with global_step\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpizx8jhl7/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 0.8039173\n",
      "INFO:tensorflow:global_step/sec: 0.90518\n",
      "INFO:tensorflow:step = 101, loss = 0.16633654 (110.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.977861\n",
      "INFO:tensorflow:step = 201, loss = 0.16473089 (102.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.97399\n",
      "INFO:tensorflow:step = 301, loss = 0.16107056 (102.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.987141\n",
      "INFO:tensorflow:step = 401, loss = 0.16161034 (101.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.982739\n",
      "INFO:tensorflow:step = 501, loss = 0.114540115 (101.757 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 576 into /tmp/tmpizx8jhl7/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.928674\n",
      "INFO:tensorflow:step = 601, loss = 0.1689183 (107.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.984061\n",
      "INFO:tensorflow:step = 701, loss = 0.13306949 (101.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.984635\n",
      "INFO:tensorflow:step = 801, loss = 0.14883676 (101.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.986253\n",
      "INFO:tensorflow:step = 901, loss = 0.16839902 (101.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.985663\n",
      "INFO:tensorflow:step = 1001, loss = 0.14120501 (101.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.985971\n",
      "INFO:tensorflow:step = 1101, loss = 0.14915127 (101.423 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1163 into /tmp/tmpizx8jhl7/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.944329\n",
      "INFO:tensorflow:step = 1201, loss = 0.1253186 (105.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.987809\n",
      "INFO:tensorflow:step = 1301, loss = 0.14359531 (101.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.982121\n",
      "INFO:tensorflow:step = 1401, loss = 0.12399317 (101.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.97509\n",
      "INFO:tensorflow:step = 1501, loss = 0.12172474 (102.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.977812\n",
      "INFO:tensorflow:step = 1601, loss = 0.15157436 (102.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.992889\n",
      "INFO:tensorflow:step = 1701, loss = 0.12277871 (100.716 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1705 into /tmp/tmpizx8jhl7/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.15091036.\n",
      "CPU times: user 8h 10min 21s, sys: 41min 52s, total: 8h 52min 14s\n",
      "Wall time: 31min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f8590f6b860>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 GPU - Main training loop: 62min 8s\n",
    "# 2 GPU - Main training loop: 44min 13s\n",
    "# 4 GPU - Main training loop: 31min 4s\n",
    "# What's a good way of adding validation data here?\n",
    "nn.train(train_input_fn, \n",
    "         max_steps=EPOCHS*(train_dataset.data_size//BATCHSIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "{'<function batch_norm at 0x7f85a00b0d90>': {'decay': 0.99, 'fused': True, 'scale': True, 'epsilon': 1.1e-05, 'data_format': 'NCHW'}, '<function convolution at 0x7f85a00a30d0>': {'activation_fn': None, 'weights_regularizer': <function l2_regularizer.<locals>.l2 at 0x7f85927be488>, 'biases_initializer': None, 'data_format': 'NCHW'}, '<function _global_avg_pool2d at 0x7f85927b1510>': {'data_format': 'NCHW'}, '<function _conv_block at 0x7f85927b1730>': {'data_format': 'NCHW'}, '<function max_pool2d at 0x7f859fded2f0>': {'data_format': 'NCHW'}, '<function avg_pool2d at 0x7f85a0089bf8>': {'data_format': 'NCHW'}}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpizx8jhl7/model.ckpt-1705\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Full AUC [0.8102469725158122, 0.8603340664566368, 0.8016955441462638, 0.8885381081992122, 0.8790134552257802, 0.9114150252965607, 0.7159372834912838, 0.84188482144457, 0.6281379505905793, 0.8428493562592735, 0.7559888501448144, 0.8037784672617188, 0.7688015185060102, 0.8932833414296647]\n",
      "Test AUC: 0.8144\n",
      "CPU times: user 18min 2s, sys: 1min 49s, total: 19min 51s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main prediction loop: 1min\n",
    "# Test AUC: 0.8150\n",
    "predictions = list(nn.predict(test_input_fn))\n",
    "y_truth = test_dataset.labels\n",
    "y_guess = np.array(predictions)\n",
    "print(\"Test AUC: {0:.4f}\".format(compute_roc_auc(y_truth, y_guess, CLASSES))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Synthetic Data (Pure Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on fake-data -> no IO lag\n",
    "batch_in_epoch = train_dataset.data_size//BATCHSIZE\n",
    "tot_num = batch_in_epoch * BATCHSIZE\n",
    "fake_X = np.random.rand(tot_num, 3, 224, 224).astype(np.float32)\n",
    "fake_y = np.random.rand(tot_num, CLASSES).astype(np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpp248ho0x\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_summary_steps': 100, '_session_config': None, '_tf_random_seed': None, '_task_id': 0, '_evaluation_master': '', '_service': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f858125bf60>, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_master': '', '_model_dir': '/tmp/tmpp248ho0x', '_keep_checkpoint_max': 5, '_global_id_in_cluster': 0}\n",
      "CPU times: user 628 µs, sys: 4.5 ms, total: 5.13 ms\n",
      "Wall time: 4.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Estimator\n",
    "if MULTI_GPU:\n",
    "    nn = tf.estimator.Estimator(model_fn=model_fn_multigpu,\n",
    "                                params={\"lr\":LR, \n",
    "                                        \"checkpoint\":CHKPOINT,\n",
    "                                        \"n_classes\":CLASSES,\n",
    "                                        \"batchsize\":BATCHSIZE,\n",
    "                                        \"gpus\":list(range(GPU_COUNT)),\n",
    "                                        \"model_name\":\"densenet121\"})\n",
    "else:\n",
    "    nn = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                params={\"lr\":LR, \n",
    "                                        \"checkpoint\":CHKPOINT,\n",
    "                                        \"n_classes\":CLASSES,\n",
    "                                        \"model_name\":\"densenet121\"})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable global_step:0 from checkpoint tf-densenet121.ckpt with global_step\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpp248ho0x/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 0.80244374\n",
      "INFO:tensorflow:global_step/sec: 1.6309\n",
      "INFO:tensorflow:step = 101, loss = 0.693112 (61.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86052\n",
      "INFO:tensorflow:step = 201, loss = 0.693772 (53.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85498\n",
      "INFO:tensorflow:step = 301, loss = 0.6959225 (53.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85498\n",
      "INFO:tensorflow:step = 401, loss = 0.69358575 (53.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82027\n",
      "INFO:tensorflow:step = 501, loss = 0.6940733 (54.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83615\n",
      "INFO:tensorflow:step = 601, loss = 0.694589 (54.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82951\n",
      "INFO:tensorflow:step = 701, loss = 0.69239223 (54.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81981\n",
      "INFO:tensorflow:step = 801, loss = 0.69134533 (54.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82534\n",
      "INFO:tensorflow:step = 901, loss = 0.6928448 (54.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81149\n",
      "INFO:tensorflow:step = 1001, loss = 0.69275934 (55.204 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1079 into /tmp/tmpp248ho0x/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.66979\n",
      "INFO:tensorflow:step = 1101, loss = 0.6891719 (59.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81127\n",
      "INFO:tensorflow:step = 1201, loss = 0.6933668 (55.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81752\n",
      "INFO:tensorflow:step = 1301, loss = 0.6921453 (55.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79749\n",
      "INFO:tensorflow:step = 1401, loss = 0.69163674 (55.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81748\n",
      "INFO:tensorflow:step = 1501, loss = 0.68945 (55.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81526\n",
      "INFO:tensorflow:step = 1601, loss = 0.6902121 (55.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82467\n",
      "INFO:tensorflow:step = 1701, loss = 0.69269955 (54.805 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1705 into /tmp/tmpp248ho0x/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.69060624.\n",
      "CPU times: user 41min 17s, sys: 14min 50s, total: 56min 8s\n",
      "Wall time: 17min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f73982e4e80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 4 GPU - Main training loop: 31min 4s\n",
    "# 4 GPU - Synthetic data: 17min 10s\n",
    "nn.train(tf.estimator.inputs.numpy_input_fn(\n",
    "    fake_X,\n",
    "    fake_y,\n",
    "    shuffle=False,\n",
    "    num_epochs=EPOCHS,\n",
    "    batch_size=BATCHSIZE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
