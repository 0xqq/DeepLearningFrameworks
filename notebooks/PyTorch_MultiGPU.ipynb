{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Summary\n",
    "# 1. PyTorch Multi-GPU example\n",
    "# 2. On-the-fly data-augmentation (random crop, random flip)\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from common.utils import download_data_chextxray, get_imgloc_labels, get_train_valid_test_split\n",
    "from common.utils import compute_roc_auc, get_cuda_version, get_cudnn_version, get_gpu_name\n",
    "from common.params_dense import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "PyTorch:  0.3.1.post2\n",
      "Numpy:  1.13.3\n",
      "GPU:  ['Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs:  24\n",
      "GPUs:  4\n"
     ]
    }
   ],
   "source": [
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "GPU_COUNT = len(get_gpu_name())\n",
    "print(\"CPUs: \", CPU_COUNT)\n",
    "print(\"GPUs: \", GPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestxray/images chestxray/Data_Entry_2017.csv\n"
     ]
    }
   ],
   "source": [
    "# Model-params\n",
    "IMAGENET_RGB_MEAN_TORCH = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_SD_TORCH = [0.229, 0.224, 0.225]\n",
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "print(IMAGE_FOLDER, LABEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually scale to multi-gpu\n",
    "if MULTI_GPU:\n",
    "    assert torch.cuda.is_available()\n",
    "     # enables cudnn's auto-tuner\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    LR *= GPU_COUNT \n",
    "    BATCHSIZE *= GPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 677 ms, sys: 237 ms, total: 914 ms\n",
      "Wall time: 912 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayData(Dataset):\n",
    "    def __init__(self, img_dir, lbl_file, patient_ids, transform=None):\n",
    "        \n",
    "        self.img_locs, self.labels = get_imgloc_labels(img_dir, lbl_file, patient_ids)\n",
    "        self.transform = transform\n",
    "        print(\"Loaded {} labels and {} images\".format(len(self.labels), len(self.img_locs)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_file = self.img_locs[idx]\n",
    "        im_rgb = Image.open(im_file).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            im_rgb = self.transform(im_rgb)\n",
    "        return im_rgb, torch.FloatTensor(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:21563 valid:3080 test:6162\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set, test_set = get_train_valid_test_split(TOT_PATIENT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise by imagenet mean/sd\n",
    "normalize = transforms.Normalize(IMAGENET_RGB_MEAN_TORCH,\n",
    "                                 IMAGENET_RGB_SD_TORCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87306 labels and 87306 images\n"
     ]
    }
   ],
   "source": [
    "# Dataset for training\n",
    "train_dataset = XrayData(img_dir=IMAGE_FOLDER,\n",
    "                         lbl_file=LABEL_FILE,\n",
    "                         patient_ids=train_set,\n",
    "                         transform=transforms.Compose([\n",
    "                             transforms.Resize(WIDTH+40),\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "                             transforms.RandomResizedCrop(size=WIDTH),\n",
    "                             transforms.ToTensor(),  # need to convert image to tensor!\n",
    "                             normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_augmentation_dataset(img_dir, lbl_file, patient_ids, normalize):\n",
    "    dataset = XrayData(img_dir, lbl_file, patient_ids,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize(WIDTH),\n",
    "                           transforms.ToTensor(),  \n",
    "                           normalize]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7616 labels and 7616 images\n",
      "Loaded 17198 labels and 17198 images\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = no_augmentation_dataset(IMAGE_FOLDER, LABEL_FILE, valid_set, normalize)\n",
    "test_dataset = no_augmentation_dataset(IMAGE_FOLDER, LABEL_FILE, test_set, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(model_name='densenet121', out_features=CLASSES, multi_gpu=MULTI_GPU):\n",
    "    if model_name == 'densenet121':\n",
    "        model = models.densenet.densenet121(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model-name\")\n",
    "    # Replace classifier (FC-1000) with (FC-14)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(model.classifier.in_features, out_features), \n",
    "        nn.Sigmoid())\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    # CUDA\n",
    "    model.cuda()  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_symbol(sym, lr=LR):\n",
    "    opt = optim.Adam(sym.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "    # BCE Loss since classes not mutually exclusive + Sigmoid FC-layer\n",
    "    cri = nn.BCELoss()\n",
    "    sch = ReduceLROnPlateau(opt, factor=0.1, patience=5, mode='min')\n",
    "    return opt, cri, sch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, epoch, batch=BATCHSIZE):\n",
    "    model.train()\n",
    "    print(\"Training epoch {}\".format(epoch+1))\n",
    "    loss_val = 0\n",
    "    loss_cnt = 0\n",
    "    for data, target in dataloader:\n",
    "        # Get samples\n",
    "        data = Variable(torch.FloatTensor(data).cuda())\n",
    "        target = Variable(torch.FloatTensor(target).cuda())\n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "        # Forwards\n",
    "        output = model(data)\n",
    "        # Loss\n",
    "        loss = criterion(output, target)\n",
    "        # Back-prop\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "         # Log the loss\n",
    "        loss_val += loss.data[0]\n",
    "        loss_cnt += 1\n",
    "    print(\"Training loss: {0:.4f}\".format(loss_val/loss_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, dataloader, criterion, epoch, phase='valid', \n",
    "                batch=BATCHSIZE, cl=CLASSES):\n",
    "    model.eval()\n",
    "    if phase == 'testing':\n",
    "        print(\"Testing epoch {}\".format(epoch+1))\n",
    "    else:\n",
    "        print(\"Validating epoch {}\".format(epoch+1))\n",
    "    out_pred = torch.FloatTensor().cuda()\n",
    "    out_gt = torch.FloatTensor().cuda()\n",
    "    loss_val = 0\n",
    "    loss_cnt = 0\n",
    "    for data, target in dataloader:\n",
    "        # Get samples\n",
    "        data = Variable(torch.FloatTensor(data).cuda(), volatile=True)\n",
    "        target = Variable(torch.FloatTensor(target).cuda(), volatile=True)\n",
    "         # Forwards\n",
    "        output = model(data)\n",
    "        # Loss\n",
    "        loss = criterion(output, target)\n",
    "        # Log the loss\n",
    "        loss_val += loss.data[0]\n",
    "        loss_cnt += 1\n",
    "        # Log for AUC\n",
    "        out_pred = torch.cat((out_pred, output.data), 0)\n",
    "        out_gt = torch.cat((out_gt, target.data), 0)\n",
    "        \n",
    "    loss_mean = loss_val/loss_cnt\n",
    "    out_gt = out_gt.cpu().numpy()\n",
    "    out_pred = out_pred.cpu().numpy()    \n",
    "    \n",
    "    if phase == 'testing':\n",
    "        print(\"Test-Dataset loss: {0:.4f}\".format(loss_mean))\n",
    "        print(\"Test-Dataset AUC: {0:.4f}\".format(compute_roc_auc(out_gt, out_pred, cl)))\n",
    "    else:\n",
    "        print(\"Validation loss: {0:.4f}\".format(loss_mean))\n",
    "        print(\"Validation AUC: {0:.4f}\".format(compute_roc_auc(out_gt, out_pred, cl)))\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def print_learning_rate(opt):\n",
    "#    for param_group in opt.param_groups:\n",
    "#        print(\"Learning rate: \", param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "# pin_memory brings errors on 4 GPUs\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCHSIZE,\n",
    "                          shuffle=True, num_workers=CPU_COUNT)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=16*BATCHSIZE,\n",
    "                          shuffle=False, num_workers=CPU_COUNT)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16*BATCHSIZE,\n",
    "                         shuffle=False, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Train CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 1.13 s, total: 3.35 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "chexnet_sym = get_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 ms, sys: 651 µs, total: 2.44 ms\n",
      "Wall time: 2.44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load optimiser, loss\n",
    "optimizer, criterion, scheduler = init_symbol(chexnet_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "Training loss: 0.1765\n",
      "Validating epoch 1\n",
      "Validation loss: 0.1465\n",
      "Full AUC [0.78047291141014863, 0.85909709257731659, 0.79313340327537063, 0.89749585481278071, 0.88902768719504432, 0.88417097082600271, 0.73219555250064428, 0.77342887194320264, 0.63866618059683533, 0.78288408887573402, 0.69191230275625271, 0.76299611198343886, 0.77486246478541076, 0.82977652127406942]\n",
      "Validation AUC: 0.7922\n",
      "Epoch time: 331 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 2\n",
      "Training loss: 0.1587\n",
      "Validating epoch 2\n",
      "Validation loss: 0.1434\n",
      "Full AUC [0.79259991764788329, 0.87961620283940434, 0.79103080177880947, 0.9138484475393307, 0.89165424067012866, 0.90535563764729854, 0.73628062830496699, 0.83243491980015782, 0.64618240577587183, 0.80816801989367026, 0.69311906236123366, 0.77096529732445951, 0.79035331077884452, 0.85832081521030246]\n",
      "Validation AUC: 0.8079\n",
      "Epoch time: 272 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 3\n",
      "Training loss: 0.1561\n",
      "Validating epoch 3\n",
      "Validation loss: 0.1405\n",
      "Full AUC [0.79878716796327454, 0.88844737261031281, 0.79739007071090373, 0.91821705956137256, 0.90252894964021002, 0.91299705261728725, 0.78493364680887634, 0.83331580331317379, 0.66018798385841249, 0.82146238208313982, 0.72129450688281394, 0.78568869468342151, 0.81521184496576082, 0.87269812234101385]\n",
      "Validation AUC: 0.8224\n",
      "Epoch time: 267 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 4\n",
      "Training loss: 0.1548\n",
      "Validating epoch 4\n",
      "Validation loss: 0.1471\n",
      "Full AUC [0.77702770185029435, 0.87461757767840342, 0.78361682180405801, 0.91222717203078951, 0.90243928401002016, 0.91676755276720212, 0.78021354870457016, 0.89759400473310547, 0.64246451336404553, 0.80335537512528843, 0.69856042553989905, 0.79487030516521662, 0.78914125713403638, 0.8620853706256445]\n",
      "Validation AUC: 0.8168\n",
      "Epoch time: 267 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 5\n",
      "Training loss: 0.1531\n",
      "Validating epoch 5\n",
      "Validation loss: 0.1426\n",
      "Full AUC [0.80187789108494534, 0.89656362610168017, 0.80253465479140151, 0.92189384325356982, 0.90436502030105648, 0.91447922972047946, 0.77074054691588489, 0.89804102024717325, 0.65103293156278308, 0.83465068356462646, 0.73504137193463048, 0.78419979176254206, 0.80931308860712459, 0.87458565310110481]\n",
      "Validation AUC: 0.8285\n",
      "Epoch time: 265 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "CPU times: user 15min 9s, sys: 3min 22s, total: 18min 31s\n",
      "Wall time: 23min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1 GPU - Main training loop: 41min 46s\n",
    "# 2 GPU - Main training loop: 28min 50s\n",
    "# 4 GPU - Main training loop: 23min 21s\n",
    "loss_min = float(\"inf\")    \n",
    "# Main train/val loop\n",
    "for j in range(EPOCHS):\n",
    "    stime = time.time()\n",
    "    train_epoch(chexnet_sym, train_loader, optimizer, criterion, j)\n",
    "    loss_val = valid_epoch(chexnet_sym, valid_loader, criterion, j)\n",
    "    # LR Schedule\n",
    "    scheduler.step(loss_val)\n",
    "    #print_learning_rate(optimizer)\n",
    "    \n",
    "    # I comment this out to create a fair test against Keras\n",
    "    # Keras cannot checkpoint multi-gpu models at the moment\n",
    "    \n",
    "    #if loss_val < loss_min:\n",
    "    #    print(\"Loss decreased. Saving ...\")\n",
    "    #    loss_min = loss_val\n",
    "    #    torch.save({'epoch': j + 1, \n",
    "    #                'state_dict': chexnet_sym.state_dict(), \n",
    "    #                'best_loss': loss_min, \n",
    "    #                'optimizer' : optimizer.state_dict()}, 'best_chexnet.pth.tar')\n",
    "    \n",
    "    etime = time.time()\n",
    "    print(\"Epoch time: {0:.0f} seconds\".format(etime-stime))\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Test CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 11.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model for testing\n",
    "# I comment this out to create a fair test against Keras\n",
    "#chexnet_sym_test = get_symbol()\n",
    "#chkpt = torch.load(\"best_chexnet.pth.tar\")\n",
    "#chexnet_sym_test.load_state_dict(chkpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch 0\n",
      "Test-Dataset loss: 0.1551\n",
      "Full AUC [0.80900915420799102, 0.8564088054052984, 0.80980249343110633, 0.89542340207516835, 0.88405172137731636, 0.91704036798357114, 0.71490761109990131, 0.84365424931462663, 0.61177499606708541, 0.84742658911735802, 0.74123303381766514, 0.80207797837116268, 0.75559573842670769, 0.87707956205007109]\n",
      "Test-Dataset AUC: 0.8118\n",
      "CPU times: user 7.37 s, sys: 6.33 s, total: 13.7 s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Evaluate\n",
    "# AUC: 0.8118\n",
    "#test_loss = valid_epoch(chexnet_sym_test, test_loader, criterion, -1, 'testing')\n",
    "test_loss = valid_epoch(chexnet_sym, test_loader, criterion, -1, 'testing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
