{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Create a data-augmentor + data-preprocessing class\n",
    "# Using cv2 not pil and maybe using https://github.com/aleju/imgaug\n",
    "# Will ensure that pre-processing + augmentation standardised across frameworks\n",
    "# Also maybe PIL is bottlenecking pytorch?\n",
    "\n",
    "# Notes\n",
    "# http://corochann.com/install-chainer-1401.html#Install_NCCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Downloaded from https://github.com/KaimingHe/deep-residual-networks\n",
    "#cd /home/iliauk/.chainer/dataset/pfnet/chainer/models/\n",
    "#wget -N https://ikpublictutorial.blob.core.windows.net/deeplearningframeworks/ResNet-50-model.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/cupy/core/fusion.py:659: FutureWarning: cupy.core.fusion is experimental. The interface can change in the future.\n",
      "  util.experimental('cupy.core.fusion')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers, cuda, dataset, training\n",
    "from chainer.training import extensions, updaters, StandardUpdater\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.links import ResNet50Layers\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import random\n",
    "#import cv2\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Improvement\n",
    "# 1. Auto-tune\n",
    "# This adds very little now .. not sure if True by default?\n",
    "chainer.global_config.autotune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Chainer:  4.0.0b1\n",
      "CuPy:  4.0.0b1\n",
      "Numpy:  1.14.2\n",
      "GPU:  ['Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n",
      "CPUs:  24\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Chainer: \", chainer.__version__)\n",
    "print(\"CuPy: \", chainer.cuda.cupy.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "print(\"CPUs: \", CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"num_gpus\"\n",
    "NUM_GPUS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_GPU=NUM_GPUS>1\n",
    "DEVICES=tuple(list(range(NUM_GPUS)))\n",
    "if MULTI_GPU:\n",
    "    from cupy.cuda import nccl  # Test that nccl works for multi-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "CLASSES = 14\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "LR = 0.0001  # Effective learning-rate will decrease as BATCHSIZE rises\n",
    "EPOCHS = 5\n",
    "#BATCHSIZE = 64*NUM_GPUS\n",
    "BATCHSIZE = 64  # Chainer auto scales batch\n",
    "IMAGENET_RGB_MEAN =  np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_RGB_SD =  np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "TOT_PATIENT_NUMBER = 30805  # From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestxray/images chestxray/Data_Entry_2017.csv\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "print(IMAGE_FOLDER, LABEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 786 ms, sys: 256 ms, total: 1.04 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayData(dataset.DatasetMixin):\n",
    "    def __init__(self, patient_ids, img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, augmentation=None):\n",
    "        # Read labels-csv\n",
    "        df = pd.read_csv(lbl_file)\n",
    "        \n",
    "        # Split labels on unfiltered data\n",
    "        df_label = df['Finding Labels'].str.split(\n",
    "            '|', expand=False).str.join(sep='*').str.get_dummies(sep='*')\n",
    "        \n",
    "        # Filter by patient-ids (both)\n",
    "        df_label['Patient ID'] = df['Patient ID']\n",
    "        df_label = df_label[df_label['Patient ID'].isin(patient_ids)]\n",
    "        df = df[df['Patient ID'].isin(patient_ids)]\n",
    "        \n",
    "        # Remove unncessary columns\n",
    "        df_label.drop(['Patient ID','No Finding'], axis=1, inplace=True)  \n",
    "        \n",
    "        # List of images (full-path)\n",
    "        self.img_locs =  df['Image Index'].map(lambda im: os.path.join(img_dir, im)).values\n",
    "        # One-hot encoded labels (float32 for BCE loss)\n",
    "        self.labels = df_label.values\n",
    "        \n",
    "        # Processing\n",
    "        self.augmentation = augmentation\n",
    "        print(\"Loaded {} labels and {} images\".format(len(self.labels), len(self.img_locs)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_locs)   \n",
    "    \n",
    "    def get_example(self, idx):\n",
    "        im_file = self.img_locs[idx]\n",
    "        # RGB Image\n",
    "        im_rgb = Image.open(im_file).convert('RGB')\n",
    "        im_rgb = _apply_data_preprocessing(im_rgb)\n",
    "        label = self.labels[idx]\n",
    "        if self.augmentation is not None:\n",
    "            im_rgb = _apply_data_augmentation(im_rgb)\n",
    "        return np.array(im_rgb, dtype=np.float32), np.array(label, dtype=np.int32)\n",
    "    \n",
    "def _apply_data_preprocessing(rgb_im, w=WIDTH, h=HEIGHT, \n",
    "                              rgb_m=IMAGENET_RGB_MEAN, rgb_sd=IMAGENET_RGB_SD):\n",
    "    # REDO Method!\n",
    "    # https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L325\n",
    "    # Resize\n",
    "    rgb_im = rgb_im.resize((w, h), Image.NEAREST)\n",
    "    # Array\n",
    "    im = np.asarray(rgb_im, dtype=np.float32)\n",
    "    # (w, h, c) to (c, h, w)\n",
    "    im = im.transpose(2, 0, 1)\n",
    "    # Normalise image with imagenet-values\n",
    "    # This is torch-model normalisation\n",
    "    # Ref: https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py\n",
    "    im = im / 255.\n",
    "    im = (im - rgb_m[:, None, None]) / rgb_sd[:, None, None]\n",
    "    return im\n",
    "\n",
    "def _apply_data_augmentation(x):\n",
    "    # REDO Method!\n",
    "    # Random horizontal flip\n",
    "    # col_axis = 2\n",
    "    if random.randint(0, 1):\n",
    "        x = x.swapaxes(2, 0)\n",
    "        x = x[::-1, ...]\n",
    "        x = x.swapaxes(0, 2)\n",
    "    # Random rotation\n",
    "    # ...\n",
    "    # Random crop/zoom\n",
    "    # ...\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:21563 valid:3080 test:6162\n"
     ]
    }
   ],
   "source": [
    "# Training / Valid / Test split (70% / 10% / 20%)\n",
    "train_set, other_set = train_test_split(\n",
    "    range(1,TOT_PATIENT_NUMBER+1), train_size=0.7, test_size=0.3, shuffle=False)\n",
    "valid_set, test_set = train_test_split(other_set, train_size=1/3, test_size=2/3, shuffle=False)\n",
    "print(\"train:{} valid:{} test:{}\".format(\n",
    "    len(train_set), len(valid_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87306 labels and 87306 images\n",
      "Loaded 7616 labels and 7616 images\n",
      "Loaded 17198 labels and 17198 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=train_set, augmentation=True)\n",
    "valid_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=valid_set, augmentation=False)\n",
    "test_dataset  = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=test_set, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chexnet(ResNet50Layers):\n",
    "    \n",
    "    def __init__(self, pretrained_model=\"auto\", basemodel_out='pool5', out_features=CLASSES):\n",
    "        super(chexnet, self).__init__(pretrained_model)\n",
    "        self._basemodel_out = basemodel_out\n",
    "        in_features = 2048\n",
    "        with self.init_scope():\n",
    "            self.classifier = L.Linear(in_features, out_features)\n",
    "    \n",
    "    def __call__(self, x, **kwargs):\n",
    "        h = super(chexnet, self).__call__(x, layers=[self._basemodel_out], **kwargs)[self._basemodel_out]\n",
    "        h = self.classifier(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(model_name='densenet121', multi_gpu=MULTI_GPU):\n",
    "    if model_name == 'resnet50':\n",
    "        m = chexnet()\n",
    "    elif model_name == 'densenet121':\n",
    "        # https://github.com/chainer/chainer/issues/4426\n",
    "        raise ValueError(\"Densenet is not yet officially implemented in Chainer\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model-name\")\n",
    "    # CUDA\n",
    "    if not multi_gpu:\n",
    "        print(\"One GPU\")\n",
    "        chainer.cuda.get_device(0).use()  # Make a specified GPU current\n",
    "        m.to_gpu()  \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_symbol(sym, lr=LR):\n",
    "    opt = optimizers.Adam(alpha=lr, beta1=0.9, beta2=0.999)\n",
    "    opt.setup(sym)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc(data_gt, data_pd, full=True, classes=CLASSES):\n",
    "    roc_auc = []\n",
    "    for i in range(classes):\n",
    "        roc_auc.append(roc_auc_score(data_gt[:, i], data_pd[:, i]))\n",
    "    print(\"Full AUC\", roc_auc)\n",
    "    roc_auc = np.mean(roc_auc)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfun(x, t):\n",
    "    return F.sigmoid_cross_entropy(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 387 ms, sys: 95.8 ms, total: 483 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "predictor = get_symbol(model_name='resnet50')\n",
    "chexnet_sym = L.Classifier(predictor, lossfun=lossfun)\n",
    "chexnet_sym.compute_accuracy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 558 µs, sys: 162 µs, total: 720 µs\n",
      "Wall time: 727 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load optimiser\n",
    "optimizer = init_symbol(chexnet_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data-iterators\n",
    "# Open-CV runs on GPU by default!\n",
    "# Weird-bug to set shared_mem (set random value and adjust)\n",
    "if MULTI_GPU:\n",
    "    train_iters = [\n",
    "        chainer.iterators.MultiprocessIterator(\n",
    "            train_dataset, BATCHSIZE, n_prefetch=10, n_processes=int(CPU_COUNT/len(DEVICES))) \n",
    "        for i in chainer.datasets.split_dataset_n_random(train_dataset, len(DEVICES))]\n",
    "else:\n",
    "    train_iter = chainer.iterators.MultiprocessIterator(\n",
    "        train_dataset, BATCHSIZE, n_prefetch=10, n_processes=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These can have a higher batch-size than train since no grads stored\n",
    "valid_iter = chainer.iterators.MultiprocessIterator(\n",
    "    valid_dataset, BATCHSIZE, repeat=False, shuffle=False, n_prefetch=10, n_processes=CPU_COUNT)\n",
    "test_iter = chainer.iterators.MultiprocessIterator(\n",
    "    test_dataset, BATCHSIZE, repeat=False, shuffle=False, n_prefetch=10, n_processes=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py:133: UserWarning: optimizer.eps is changed to 4e-08 by MultiprocessParallelUpdater for new batch size.\n",
      "  format(optimizer.eps))\n"
     ]
    }
   ],
   "source": [
    "# MultiprocessParallelUpdater requires NCCL.\n",
    "# https://github.com/nvidia/nccl#build--run\n",
    "if MULTI_GPU:\n",
    "    updater = updaters.MultiprocessParallelUpdater(train_iters, optimizer, devices=DEVICES)\n",
    "else:\n",
    "    updater = StandardUpdater(train_iter, optimizer, device=0)\n",
    "val_interval = (1, 'epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = training.Trainer(updater, stop_trigger=(EPOCHS, 'epoch'))\n",
    "trainer.extend(extensions.Evaluator(valid_iter, chexnet_sym, device=DEVICES[0]), trigger=val_interval)\n",
    "trainer.extend(extensions.LogReport(trigger=val_interval))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'iteration', 'main/loss', 'validation/main/loss']), trigger=val_interval)\n",
    "trainer.extend(extensions.ProgressBar(update_interval=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process _Worker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 61, in run\n",
      "    loss.backward()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/variable.py\", line 878, in backward\n",
      "    self._backward_main(retain_grad)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/variable.py\", line 979, in _backward_main\n",
      "    target_input_indexes, out_grad, in_grad)\n",
      "KeyboardInterrupt\n",
      "Process _Worker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 65, in run\n",
      "    gg = gather_grads(self.model)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 339, in gather_grads\n",
      "    return _gather(link, \"grad\")\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 322, in _gather\n",
      "    ptrs = cuda.to_gpu(ptrs)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/cuda.py\", line 296, in to_gpu\n",
      "    return cupy.asarray(array)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/cupy/creation/from_data.py\", line 61, in asarray\n",
      "    return core.array(a, dtype, False)\n",
      "KeyboardInterrupt\n",
      "Process _Worker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 65, in run\n",
      "    gg = gather_grads(self.model)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 339, in gather_grads\n",
      "    return _gather(link, \"grad\")\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 322, in _gather\n",
      "    ptrs = cuda.to_gpu(ptrs)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/cuda.py\", line 296, in to_gpu\n",
      "    return cupy.asarray(array)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/cupy/creation/from_data.py\", line 61, in asarray\n",
      "    return core.array(a, dtype, False)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magics/execution.py\", line 1230, in time\n",
      "    out = eval(code, glob, local_ns)\n",
      "  File \"<timed eval>\", line 5, in <module>\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/trainer.py\", line 299, in run\n",
      "    update()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updater.py\", line 223, in update\n",
      "    self.update_core()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 216, in update_core\n",
      "    gg = gather_grads(self._master)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 339, in gather_grads\n",
      "    return _gather(link, \"grad\")\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/training/updaters/multiprocess_parallel_updater.py\", line 322, in _gather\n",
      "    ptrs = cuda.to_gpu(ptrs)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/chainer/cuda.py\", line 296, in to_gpu\n",
      "    return cupy.asarray(array)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/cupy/creation/from_data.py\", line 61, in asarray\n",
      "    return core.array(a, dtype, False)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/inspect.py\", line 718, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/posixpath.py\", line 372, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/posixpath.py\", line 406, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/posixpath.py\", line 161, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1 GPU = 3.1864 iters/sec\n",
    "# Wall time: 36m46s\n",
    "# 2 GPU = 2.6848 iters/sec\n",
    "# Wall time: 41min9s\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Test CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can load model from checkpoint\n",
    "#model = get_symbol(model_name='resnet50')\n",
    "# Load the saved paremeters into the instance\n",
    "#serializers.load_npz('my_mnist.model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fb3fafe6f865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_truth = test_dataset.labels\\ny_guess = []\\ntest_iter.reset()\\nwith chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\\n    for test_batch in test_iter:\\n        # Data\\n        x_test, y_test = concat_examples(test_batch, device=DEVICES[0])\\n        # Prediction (need to apply sigmoid to turn into probability)\\n        pred = cuda.to_cpu(F.sigmoid(predictor(x_test)).data)\\n        # Collect results\\n        y_guess.append(pred)           \\n# Concatenate\\ny_guess = np.concatenate(y_guess, axis=0)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2129\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-62>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36mtransform_cell\u001b[0;34m(self, cell)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36mpush_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m#print(\"transformers clear\") #debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_accumulating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIPythonInputSplitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_indent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36m_update_indent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_indent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# self.source always has a trailing newline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_spaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_next_indent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_dedent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_spaces\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36mfind_next_indent\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_next_indent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;34m\"\"\"Find the number of spaces for the next line of indentation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENDMARKER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/inputsplitter.py\u001b[0m in \u001b[0;36mpartial_tokens\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEWLINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m:\u001b[0m                   \u001b[0;31m# measure leading whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                     \u001b[0mcolumn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_truth = test_dataset.labels\n",
    "y_guess = []\n",
    "test_iter.reset()\n",
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "    for test_batch in test_iter:\n",
    "        # Data\n",
    "        x_test, y_test = concat_examples(test_batch, device=DEVICES[0])\n",
    "        # Prediction (need to apply sigmoid to turn into probability)\n",
    "        pred = cuda.to_cpu(F.sigmoid(predictor(x_test)).data)\n",
    "        # Collect results\n",
    "        y_guess.append(pred)           \n",
    "# Concatenate\n",
    "y_guess = np.concatenate(y_guess, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AUC: 0.7993\n",
    "print(\"Test AUC: {0:.4f}\".format(compute_roc_auc(y_truth, y_guess)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
