{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from common.utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.4 |Anaconda custom (64-bit)| (default, Nov  3 2017, 20:01:27) \n",
      "[GCC 7.2.0]\n",
      "MXNet:  0.12.0\n",
      "Numpy:  1.13.3\n",
      "GPU:  ['Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB']\n",
      "CUDA Version 8.0.61\n",
      "CuDNN Version  6.0.21\n",
      "CPUs:  24\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"MXNet: \", mx.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "print(\"CPUs: \", CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User-set\n",
    "# Note if NUM_GPUS > 1 then MULTI_GPU = True and ALL GPUs will be used\n",
    "# Set below to affect batch-size\n",
    "# E.g. 1 GPU = 64, 2 GPUs = 64*2, 4 GPUs = 64*4\n",
    "# Note that the effective learning-rate will be decreased this way\n",
    "NUM_GPUS = 4 # Scaling factor for batch\n",
    "MULTI_GPU=NUM_GPUS>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "CLASSES = 14\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "LR = 0.0001  # Effective learning-rate will decrease as BATCHSIZE rises\n",
    "EPOCHS = 5\n",
    "BATCHSIZE = 64*NUM_GPUS\n",
    "IMAGENET_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_SD = [0.229, 0.224, 0.225]\n",
    "TOT_PATIENT_NUMBER = 30805  # From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "TRAIN_LST = os.path.join(CSV_DEST, \"train.lst\")\n",
    "VALID_LST = os.path.join(CSV_DEST, \"valid.lst\")\n",
    "TEST_LST = os.path.join(CSV_DEST, \"test.lst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 539 ms, sys: 260 ms, total: 799 ms\n",
      "Wall time: 798 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "https://github.com/apache/incubator-mxnet/issues/1480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                        0.143  0.143          NaN  \n",
       "1                        0.143  0.143          NaN  \n",
       "2                        0.168  0.168          NaN  \n",
       "3                        0.171  0.171          NaN  \n",
       "4                        0.143  0.143          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LABEL_FILE)\n",
    "df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chestxray/images/00000001_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chestxray/images/00000001_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chestxray/images/00000001_002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chestxray/images/00000002_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chestxray/images/00000003_000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atelectasis  Cardiomegaly  Consolidation  Edema  Effusion  Emphysema  \\\n",
       "0            0             1              0      0         0          0   \n",
       "1            0             1              0      0         0          1   \n",
       "2            0             1              0      0         1          0   \n",
       "3            0             0              0      0         0          0   \n",
       "4            0             0              0      0         0          0   \n",
       "\n",
       "   Fibrosis  Hernia  Infiltration  Mass  No Finding  Nodule  \\\n",
       "0         0       0             0     0           0       0   \n",
       "1         0       0             0     0           0       0   \n",
       "2         0       0             0     0           0       0   \n",
       "3         0       0             0     0           1       0   \n",
       "4         0       1             0     0           0       0   \n",
       "\n",
       "   Pleural_Thickening  Pneumonia  Pneumothorax  \\\n",
       "0                   0          0             0   \n",
       "1                   0          0             0   \n",
       "2                   0          0             0   \n",
       "3                   0          0             0   \n",
       "4                   0          0             0   \n",
       "\n",
       "                          Image_path  \n",
       "0  chestxray/images/00000001_000.png  \n",
       "1  chestxray/images/00000001_001.png  \n",
       "2  chestxray/images/00000001_002.png  \n",
       "3  chestxray/images/00000002_000.png  \n",
       "4  chestxray/images/00000003_000.png  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split labels on unfiltered data\n",
    "df_label = df['Finding Labels'].str.split('|', expand=False).str.join(sep='*').str.get_dummies(sep='*')\n",
    "df_label['Image_path'] = IMAGE_FOLDER + os.path.sep + df['Image Index']\n",
    "#df_label.drop('No Finding', axis=1, inplace=True)\n",
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78484, 16)\n",
      "(11212, 16)\n",
      "(22424, 16)\n"
     ]
    }
   ],
   "source": [
    "# Training / Valid / Test split (70% / 10% / 20%)\n",
    "df_train, df_valid, df_test = split_train_val_test(df_label, val_size=0.1, test_size=0.2)\n",
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv(TRAIN_LST, sep='\\t', header=False)\n",
    "df_valid.to_csv(VALID_LST, sep='\\t', header=False)\n",
    "df_test.to_csv(TEST_LST, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find and list file with prefix /home/hoaphumanoid/notebooks/repos/DeepLearningFrameworks/notebooks/$TRAIN_LST\n"
     ]
    }
   ],
   "source": [
    "#%tb\n",
    "%run ./common/im2rec.py $TRAIN_LST $PWD --resize 224 --center-crop --quality 90 --num-thread 24\n",
    "#run not working!?\n",
    "#python ./common/im2rec.py chestxray/train.lst $PWD --resize 250 --center-crop --quality 90 --num-thread 24\n",
    "#python ./common/im2rec.py chestxray/valid.lst $PWD --resize 250 --center-crop --quality 90 --num-thread 24\n",
    "#python ./common/im2rec.py chestxray/test.lst $PWD --resize 250 --center-crop --quality 90 --num-thread 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Loading\n",
    "https://mxnet.incubator.apache.org/architecture/note_data_loading.html#mxnet-io-python-interface\n",
    "\n",
    "https://github.com/miraclewkf/multilabel-MXNet/blob/master/train_multilabel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = mx.io.ImageRecordIter(\n",
    "    path_imgrec = \"chestxray/train.rec\",\n",
    "    data_shape = (1,WIDTH,HEIGHT),\n",
    "    path_imglist = \"chestxray/train.lst\",\n",
    "    label_width = 15,\n",
    "    batch_size = BATCHSIZE,\n",
    "    shuffle = True,\n",
    "    mean_r = IMAGENET_RGB_MEAN[0],\n",
    "    mean_g = IMAGENET_RGB_MEAN[1],\n",
    "    mean_b = IMAGENET_RGB_MEAN[2],\n",
    "    std_r = IMAGENET_RGB_SD[0],\n",
    "    std_g = IMAGENET_RGB_SD[1],\n",
    "    std_b = IMAGENET_RGB_SD[2],\n",
    "    rand_crop = 1,\n",
    "    rand_mirror = 1, #flip horizontally\n",
    "    max_rotate_angle = 10,\n",
    "    preprocess_threads = 24\n",
    ")\n",
    "\n",
    "valid = mx.io.ImageRecordIter(\n",
    "    path_imgrec = \"chestxray/valid.rec\",\n",
    "    data_shape = (1,WIDTH,HEIGHT),\n",
    "    path_imglist = \"chestxray/valid.lst\",\n",
    "    label_width = 15,\n",
    "    batch_size = BATCHSIZE,\n",
    "    shuffle = False,\n",
    "    rand_crop = 0,\n",
    "    rand_mirror = 0, #flip horizontally\n",
    "    preprocess_threads = 24\n",
    ")\n",
    "\n",
    "\n",
    "test = mx.io.ImageRecordIter(\n",
    "    path_imgrec = \"chestxray/test.rec\",\n",
    "    data_shape = (1,WIDTH,HEIGHT),\n",
    "    path_imglist = \"chestxray/test.lst\",\n",
    "    label_width = 15,\n",
    "    batch_size = BATCHSIZE,\n",
    "    shuffle = False,\n",
    "    rand_mirror = 0, #flip horizontally\n",
    "    preprocess_threads = 24\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://hackernoon.com/transfer-learning-with-mxnet-gluon-8203005afafe\n",
    "def get_symbol(model_name='densenet121', out_features=CLASSES):\n",
    "    if model_name == 'densenet121':\n",
    "        pretrained = models.densenet121(pretrained=True)\n",
    "        model = models.densenet121(classes=out_features)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model-name\")\n",
    "    model.features = pretrained.features\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_symbol(sym, lr=LR, gpus=NUM_GPUS, batch_size=BATCHSIZE, epochs=EPOCHS, num_examples=TOT_PATIENT_NUMBER, step=[5,10]):    \n",
    "    devs = [mx.gpu(i) for i in range(gpus)]   \n",
    "    model = mx.mod.Module(\n",
    "        context       = devs,\n",
    "        symbol        = sym\n",
    "    )\n",
    "    \n",
    "    # Glorot-uniform initializer\n",
    "    #model.init_params(initializer=mx.init.Xavier(rnd_type='uniform'))\n",
    "    model.output.initialize(mx.init.Xavier(rnd_type='uniform'))\n",
    "    model.init_optimizer(optimizer='Adam', \n",
    "                       optimizer_params=(('learning_rate', lr),\n",
    "                                         ('beta1', 0.9),\n",
    "                                         ('beta2', 0.999)))\n",
    "    \n",
    "    #Criterion\n",
    "    def acc(label, pred, label_width = num_class):\n",
    "        return float((label == np.round(pred)).sum()) / label_width / pred.shape[0]\n",
    "\n",
    "    def loss(label, pred):\n",
    "        loss_all = 0\n",
    "        for i in range(len(pred)):\n",
    "            loss = 0\n",
    "            loss -= label[i] * np.log(pred[i] + 1e-6) + (1.- label[i]) * np.log(1. + 1e-6 - pred[i])\n",
    "            loss_all += np.sum(loss)\n",
    "        loss_all = float(loss_all)/float(len(pred) + 0.000001)\n",
    "        return loss_all\n",
    "    \n",
    "    cri = list()\n",
    "    cri.append(mx.metric.np(acc))\n",
    "    cri.append(mx.metric.np(loss))\n",
    "    \n",
    "    #Scheduler\n",
    "    def multi_factor_scheduler(begin_epoch, epoch_size, step=step, factor=0.1):\n",
    "        step_ = [epoch_size * (x-begin_epoch) for x in step if x-begin_epoch > 0]\n",
    "    return mx.lr_scheduler.MultiFactorScheduler(step=step_, factor=factor) if len(step_) else None\n",
    "\n",
    "    epoch_size = max(int(num_examples / batch_size), 1)\n",
    "    sch=multi_factor_scheduler(epochs, epoch_size)\n",
    "    \n",
    "    return model, cri, sch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, epoch, batch=BATCHSIZE):\n",
    "    model.train()\n",
    "    print(\"Training epoch {}\".format(epoch+1))\n",
    "    loss_val = 0\n",
    "    loss_cnt = 0\n",
    "    for data, target in dataloader:\n",
    "        # Get samples\n",
    "        data = Variable(torch.FloatTensor(data).cuda())\n",
    "        target = Variable(torch.FloatTensor(target).cuda())\n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "        # Forwards\n",
    "        output = model(data)\n",
    "        # Loss\n",
    "        loss = criterion(output, target)\n",
    "        # Back-prop\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "         # Log the loss\n",
    "        loss_val += loss.data[0]\n",
    "        loss_cnt += 1\n",
    "    print(\"Training loss: {0:.4f}\".format(loss_val/loss_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_epoch(model, dataloader, criterion, epoch, phase='valid', batch=BATCHSIZE):\n",
    "    model.eval()\n",
    "    if phase == 'testing':\n",
    "        print(\"Testing epoch {}\".format(epoch+1))\n",
    "    else:\n",
    "        print(\"Validating epoch {}\".format(epoch+1))\n",
    "    out_pred = torch.FloatTensor().cuda()\n",
    "    out_gt = torch.FloatTensor().cuda()\n",
    "    loss_val = 0\n",
    "    loss_cnt = 0\n",
    "    for data, target in dataloader:\n",
    "        # Get samples\n",
    "        data = Variable(torch.FloatTensor(data).cuda(), volatile=True)\n",
    "        target = Variable(torch.FloatTensor(target).cuda(), volatile=True)\n",
    "         # Forwards\n",
    "        output = model(data)\n",
    "        # Loss\n",
    "        loss = criterion(output, target)\n",
    "        # Log the loss\n",
    "        loss_val += loss.data[0]\n",
    "        loss_cnt += 1\n",
    "        # Log for AUC\n",
    "        out_pred = torch.cat((out_pred, output.data), 0)\n",
    "        out_gt = torch.cat((out_gt, target.data), 0)\n",
    "    loss_mean = loss_val/loss_cnt\n",
    "    if phase == 'testing':\n",
    "        print(\"Test-Dataset loss: {0:.4f}\".format(loss_mean))\n",
    "        print(\"Test-Dataset AUC: {0:.4f}\".format(compute_roc_auc(out_gt, out_pred)))\n",
    "    else:\n",
    "        print(\"Validation loss: {0:.4f}\".format(loss_mean))\n",
    "        print(\"Validation AUC: {0:.4f}\".format(compute_roc_auc(out_gt, out_pred)))\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def print_learning_rate(opt):\n",
    "#    for param_group in opt.param_groups:\n",
    "#        print(\"Learning rate: \", param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "# https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/5\n",
    "# Only multi-threading not multi-processing?\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCHSIZE,\n",
    "                          shuffle=True, num_workers=4*CPU_COUNT, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=16*BATCHSIZE,\n",
    "                          shuffle=False, num_workers=4*CPU_COUNT, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16*BATCHSIZE,\n",
    "                         shuffle=False, num_workers=4*CPU_COUNT, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Train CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 s, sys: 842 ms, total: 3.04 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "chexnet_sym = get_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 ms, sys: 0 ns, total: 2.08 ms\n",
      "Wall time: 2.09 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load optimiser, loss\n",
    "optimizer, criterion, scheduler = init_symbol(chexnet_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "Training loss: 0.1835\n",
      "Validating epoch 1\n",
      "Validation loss: 0.1399\n",
      "Full AUC [0.7783534395149987, 0.8502879925903414, 0.7898415391216569, 0.9117361631705505, 0.8988459834939467, 0.8635887920256611, 0.7571184203332109, 0.7646857743886404, 0.6446231344471807, 0.7722986472214561, 0.6901967590420974, 0.7761493194059881, 0.7871873923552003, 0.8586092375224146]\n",
      "Validation AUC: 0.7960\n",
      "Epoch time: 380 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 2\n",
      "Training loss: 0.1595\n",
      "Validating epoch 2\n",
      "Validation loss: 0.1369\n",
      "Full AUC [0.7905991554527615, 0.8723404101361815, 0.7857609668866617, 0.9182412420105919, 0.9007426731723862, 0.9017025236610906, 0.7696235950229249, 0.7861688140941363, 0.653542338937953, 0.7889835886189909, 0.7111402455422756, 0.7886741450720958, 0.7868186307510016, 0.869697539153081]\n",
      "Validation AUC: 0.8089\n",
      "Epoch time: 339 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 3\n",
      "Training loss: 0.1561\n",
      "Validating epoch 3\n",
      "Validation loss: 0.1356\n",
      "Full AUC [0.7954471982758622, 0.8924571990911592, 0.7954065194907622, 0.92413124551179, 0.9047593145360254, 0.8799082973631955, 0.7869215087442493, 0.8338285564028398, 0.656445821126302, 0.8176908363996762, 0.6781316646965746, 0.7988332382861332, 0.8067803538682091, 0.8701144134639898]\n",
      "Validation AUC: 0.8172\n",
      "Epoch time: 338 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 4\n",
      "Training loss: 0.1544\n",
      "Validating epoch 4\n",
      "Validation loss: 0.1339\n",
      "Full AUC [0.8051681428721615, 0.8781494667071883, 0.794248259509761, 0.9231702560080243, 0.9071897582726467, 0.9003872329111203, 0.794423051387598, 0.8673810149881672, 0.6686992921691011, 0.8191326341847341, 0.7192043329518234, 0.791616276361583, 0.8046664065325118, 0.8808052671662814]\n",
      "Validation AUC: 0.8253\n",
      "Epoch time: 338 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training epoch 5\n",
      "Training loss: 0.1529\n",
      "Validating epoch 5\n",
      "Validation loss: 0.1348\n",
      "Full AUC [0.7852515243902438, 0.8718794772717404, 0.7965309865547593, 0.9115458578093014, 0.9061195439501409, 0.9089931944310872, 0.7943590023979318, 0.9129897449382066, 0.6701309646385304, 0.8180061035358801, 0.6942094927169133, 0.8035020179055674, 0.8110439812531892, 0.8796793298928812]\n",
      "Validation AUC: 0.8260\n",
      "Epoch time: 338 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "CPU times: user 22min 4s, sys: 3min 43s, total: 25min 48s\n",
      "Wall time: 28min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training loop: 28m53s\n",
    "loss_min = float(\"inf\")    \n",
    "# Main train/val loop\n",
    "for j in range(EPOCHS):\n",
    "    stime = time.time()\n",
    "    train_epoch(chexnet_sym, train_loader, optimizer, criterion, j)\n",
    "    loss_val = valid_epoch(chexnet_sym, valid_loader, criterion, j)\n",
    "    # LR Schedule\n",
    "    scheduler.step(loss_val)\n",
    "    #print_learning_rate(optimizer)\n",
    "    \n",
    "    # I comment this out to create a fair test against Keras\n",
    "    # Keras cannot checkpoint multi-gpu models at the moment\n",
    "    \n",
    "    #if loss_val < loss_min:\n",
    "    #    print(\"Loss decreased. Saving ...\")\n",
    "    #    loss_min = loss_val\n",
    "    #    torch.save({'epoch': j + 1, \n",
    "    #                'state_dict': chexnet_sym.state_dict(), \n",
    "    #                'best_loss': loss_min, \n",
    "    #                'optimizer' : optimizer.state_dict()}, 'best_chexnet.pth.tar')\n",
    "    \n",
    "    etime = time.time()\n",
    "    print(\"Epoch time: {0:.0f} seconds\".format(etime-stime))\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Test CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model for testing\n",
    "# I comment this out to create a fair test against Keras\n",
    "#chexnet_sym_test = get_symbol()\n",
    "#chkpt = torch.load(\"best_chexnet.pth.tar\")\n",
    "#chexnet_sym_test.load_state_dict(chkpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch 0\n",
      "Test-Dataset loss: 0.1540\n",
      "Full AUC [0.8002874678587735, 0.8327232954883196, 0.7960755212055248, 0.886545471239617, 0.8805040798213019, 0.923330137938897, 0.7402972652710587, 0.8543066530487914, 0.6278403229432927, 0.8110967774108574, 0.7306166324926078, 0.7963945586737139, 0.7731040564373898, 0.8799044890256512]\n",
      "Test-Dataset AUC: 0.8095\n",
      "CPU times: user 11.4 s, sys: 10.6 s, total: 22 s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Evaluate\n",
    "# AUC: 0.8095\n",
    "#test_loss = valid_epoch(chexnet_sym_test, test_loader, criterion, -1, 'testing')\n",
    "test_loss = valid_epoch(chexnet_sym, test_loader, criterion, -1, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Extra: IO Experiment (time on numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen_to_numpy(data_gen, bs, ch=CHANNELS, wi=WIDTH, hi=HEIGHT, cl=CLASSES):\n",
    "    x_dta = np.zeros((data_gen.__len__()*bs, ch, wi, hi), \n",
    "                   dtype=np.float32)\n",
    "    y_dta = np.zeros((data_gen.__len__()*bs, cl),\n",
    "                   dtype=np.int32)\n",
    "    c = 0\n",
    "    for x, y in data_gen:\n",
    "        ln = len(y)\n",
    "        x_dta[c*ln:(c+1)*ln] = x\n",
    "        y_dta[c*ln:(c+1)*ln] = y\n",
    "        c+= 1\n",
    "    return x_dta, y_dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 17.3 s, total: 39 s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train, y_train = data_gen_to_numpy(train_loader, BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 5.08 s, total: 6.86 s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_val, y_val = data_gen_to_numpy(valid_loader, 16*BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87424, 3, 224, 224) (87424, 14)\n",
      "(8192, 3, 224, 224) (8192, 14)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = yield_mb(x_train, y_train, BATCHSIZE, shuffle=False)\n",
    "valid_loader = yield_mb(x_val, y_val, BATCHSIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "Training loss: 0.1426\n",
      "Validating epoch 0\n",
      "Validation loss: 0.1181\n",
      "Full AUC [0.7325276556792604, 0.8143018460329929, 0.6344205025402343, 0.7513804306120363, 0.8940063333242, 0.9349639412633591, 0.8541304263464525, 0.9589464678562699, 0.5537374593754416, 0.8553994709891826, 0.7931636873466525, 0.7896508852649442, 0.7662702585788976, 0.8515950708399794]\n",
      "Validation AUC: 0.7989\n",
      "Epoch time: 280 seconds\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "CPU times: user 4min 37s, sys: 34.3 s, total: 5min 12s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Time for one epoch is 280s vs 340s with data-generator (60s of IO lag)\n",
    "stime = time.time()\n",
    "train_epoch(chexnet_sym, train_loader, optimizer, criterion, -1)\n",
    "loss_val = valid_epoch(chexnet_sym, valid_loader, criterion, -1)\n",
    "scheduler.step(loss_val)\n",
    "etime = time.time()\n",
    "print(\"Epoch time: {0:.0f} seconds\".format(etime-stime))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
